{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Training SSD with MobileNet V3 Large**\n",
        "\n",
        "This notebook provides a step-by-step guide to train the SSD model with a MobileNet V3 Large 320 FPN backbone, specifically designed for vehicle detection tasks."
      ],
      "metadata": {
        "id": "prMGdF8OAkvz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** This notebook only guides you for detecting a single class, so adjust code according to your needs. Annd adjust parameters like number of epochs, learning rate(**lr**), weight decay, momentum as per your requirements."
      ],
      "metadata": {
        "id": "vp6e-CUf3HhE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prerequisites\n",
        "\n",
        "Ensure you have the following libraries installed:\n",
        "- PyTorch\n",
        "- torchvision\n",
        "- PIL\n",
        "- pycocotools\n",
        "- numpy\n",
        "- tqdm\n",
        "- json"
      ],
      "metadata": {
        "id": "IZKa0ZtPA21s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision\n",
        "!pip install pillow\n",
        "!pip install numpy\n",
        "!pip install tqdm\n",
        "!pip install pycocotools\n",
        "!pip install tensorboard"
      ],
      "metadata": {
        "id": "kNjycpsVA-OB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Dataset Preparation\n",
        "\n",
        "Refer to the following video for guidelines on how to obtain, label (in COCO format), and use a dataset for SSD model training: [COCO Dataset Preparation Video](https://youtu.be/O-ZPxTpb2Yg?feature=shared)"
      ],
      "metadata": {
        "id": "asrykQ1JBZ3o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cell for Downloading Dataset\n",
        "\n",
        "Use the cell below to paste the code for downloading your dataset from Roboflow or another source."
      ],
      "metadata": {
        "id": "4K3HK96jBaSs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J6XoEgnisELq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Enable GPU on Google Colab\n",
        "\n",
        "If you're using Google Colab, follow this guide to enable GPU acceleration: [Enabling GPU in Google Colab](https://www.geeksforgeeks.org/how-to-use-gpu-in-google-colab/)"
      ],
      "metadata": {
        "id": "ficatlVfCCJA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Import Libraries\n",
        "This step is essential to import necessary libraries."
      ],
      "metadata": {
        "id": "hjJENYEACOiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torchvision.transforms import functional as F\n",
        "from PIL import Image, ImageDraw\n",
        "from torchvision import transforms, models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models.detection import ssdlite320_mobilenet_v3_large\n",
        "from torch.optim import SGD\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import json"
      ],
      "metadata": {
        "id": "x0dRmV-kCUj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Define Custom Dataset Class\n",
        "\n",
        "Modify the file paths for your dataset and annotations here."
      ],
      "metadata": {
        "id": "Eq9J8zzwCrpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VehiclesDataset(Dataset):\n",
        "    def __init__(self, annotation_file, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.coco = COCO(annotation_file)\n",
        "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        coco = self.coco\n",
        "        img_id = self.ids[idx]\n",
        "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
        "        coco_annotation = coco.loadAnns(ann_ids)\n",
        "        path = coco.loadImgs(img_id)[0]['file_name']\n",
        "\n",
        "        img = Image.open(os.path.join(self.root_dir, path)).convert('RGB')\n",
        "\n",
        "        num_objs = len(coco_annotation)\n",
        "        boxes = []\n",
        "        labels = []\n",
        "\n",
        "        for i in range(num_objs):\n",
        "            if coco_annotation[i]['category_id'] == 1:  # Assuming '1' is for 'Vehicles'\n",
        "                xmin = coco_annotation[i]['bbox'][0]\n",
        "                ymin = coco_annotation[i]['bbox'][1]\n",
        "                xmax = xmin + coco_annotation[i]['bbox'][2]\n",
        "                ymax = ymin + coco_annotation[i]['bbox'][3]\n",
        "                boxes.append([xmin, ymin, xmax, ymax])\n",
        "                labels.append(coco_annotation[i]['category_id'])\n",
        "\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "\n",
        "        target = {'boxes': boxes, 'labels': labels, 'image_id': torch.tensor([img_id])}\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "def collate_fn(batch):\n",
        "  batch = [data for data in batch if data is not None and data[0] is not None]\n",
        "  return tuple(zip(*batch))\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "# Replace with your dataset paths\n",
        "train_dataset = VehiclesDataset(r'<your_train_annotations.json>', r'<your_train_dataset_path>', transform)\n",
        "val_dataset = VehiclesDataset(r'<your_val_annotations.json>', r'<your_val_dataset_path>', transform)"
      ],
      "metadata": {
        "id": "oULiPqwJCvrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Data Loaders\n",
        "\n",
        "Set up data loaders for training and validation datasets. Play around in choosing number of batches to see what suits you best.bold text"
      ],
      "metadata": {
        "id": "kp-QjK6WElYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "w93LWMCfFEBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Initialize the Model\n"
      ],
      "metadata": {
        "id": "zzw9Uf5wnJcy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For First-Time Training"
      ],
      "metadata": {
        "id": "JkBJ-ge0tAp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ssdlite320_mobilenet_v3_large(pretrained=True)"
      ],
      "metadata": {
        "id": "zrLzDEB0nQ2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For Training from a Checkpoint"
      ],
      "metadata": {
        "id": "vMPT7iZEtWAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model from the pretrained model\n",
        "model = ssdlite320_mobilenet_v3_large(pretrained=True)\n",
        "\n",
        "# Load the pretrained weights\n",
        "model.load_state_dict(torch.load(r'<your_model_name>.pth'))"
      ],
      "metadata": {
        "id": "Xof9MVXEtgVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Set Up Training Utilities\n",
        "\n",
        "Configure the device, optimizer, learning rate scheduler, and TensorBoard writer."
      ],
      "metadata": {
        "id": "WuEFvNzVtvFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
        "lr_scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3)\n",
        "writer = SummaryWriter()"
      ],
      "metadata": {
        "id": "lbHxN23ct2VY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8: Training Loop\n",
        "\n",
        "This cell will train the model and save checkpoints after each epoch."
      ],
      "metadata": {
        "id": "MsP7jLnTua-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, data_loader, device, coco_gt):\n",
        "    model.eval()\n",
        "    results = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, targets in data_loader:\n",
        "            images = list(img.to(device) for img in images)\n",
        "            outputs = model(images)\n",
        "\n",
        "            for i, output in enumerate(outputs):\n",
        "                image_id = targets[i]['image_id'].item()\n",
        "                for box, score, label in zip(output['boxes'], output['scores'], output['labels']):\n",
        "                    box = box.to('cpu').numpy()\n",
        "                    score = score.to('cpu').numpy()\n",
        "                    label = label.to('cpu').numpy()\n",
        "\n",
        "                    result = {\n",
        "                        \"image_id\": image_id,\n",
        "                        \"category_id\": int(label),\n",
        "                        \"bbox\": [box[0], box[1], box[2] - box[0], box[3] - box[1]],  # Convert to x,y,w,h format\n",
        "                        \"score\": score\n",
        "                    }\n",
        "                    results.append(result)\n",
        "\n",
        "    if results:\n",
        "        coco_dt = coco_gt.loadRes(results)  # Load predictions\n",
        "        coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
        "        coco_eval.evaluate()\n",
        "        coco_eval.accumulate()\n",
        "        coco_eval.summarize()\n",
        "        mAP = coco_eval.stats[0]  # Average Precision IoU=0.50:0.95\n",
        "    else:\n",
        "        mAP = 0\n",
        "\n",
        "    return mAP"
      ],
      "metadata": {
        "id": "hfd0OB8uwWMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(epoch, model, optimizer, lr_scheduler, save_path):\n",
        "    \"\"\"Saves a checkpoint of the current model state.\"\"\"\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'lr_scheduler_state_dict': lr_scheduler.state_dict() if lr_scheduler else None,\n",
        "    }, save_path)\n",
        "\n",
        "num_epochs = 300\n",
        "checkpoint_path = 'ssd_checkpoint.pth'\n",
        "\n",
        "val_annotation_path = r'<your_val_annotations.json>'\n",
        "val_coco_gt = COCO(val_annotation_path)\n",
        "\n",
        "try:\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, targets in tqdm(train_loader):\n",
        "            # Filter out images without any annotations\n",
        "            valid_images, valid_targets = zip(*[(img, target) for img, target in zip(images, targets) if target['boxes'].size(0) != 0])\n",
        "\n",
        "            # Skip batch if no valid images are found\n",
        "            if not valid_images:\n",
        "                continue\n",
        "\n",
        "            valid_images = list(img.to(device) for img in valid_images)\n",
        "            valid_targets = [{k: v.to(device) for k, v in t.items()} for t in valid_targets]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss_dict = model(valid_images, valid_targets)\n",
        "            losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "            if losses.item() != 0:\n",
        "                losses.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            running_loss += losses.item()\n",
        "\n",
        "        # Calculate training loss for the epoch\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        writer.add_scalar('Training loss', train_loss, epoch)\n",
        "\n",
        "        # Validation step\n",
        "        mAP = evaluate(model, val_loader, device, val_coco_gt)\n",
        "        writer.add_scalar('Validation Loss', epoch)\n",
        "        writer.add_scalar('Validation mAP', mAP, epoch)\n",
        "\n",
        "        # Step the learning rate scheduler with the validation mAP\n",
        "        lr_scheduler.step(mAP)\n",
        "\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Training Loss: {train_loss:.4f}, Validation mAP: {mAP:.4f}\")\n",
        "\n",
        "        # Save checkpoint at the end of the epoch\n",
        "        save_checkpoint(epoch, model, optimizer, lr_scheduler, checkpoint_path)\n",
        "        print(f\"Checkpoint saved for epoch {epoch + 1}\")\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Training interrupted, saving current model state...\")\n",
        "    save_checkpoint(epoch, model, optimizer, lr_scheduler, checkpoint_path)\n",
        "    print(\"Checkpoint saved.\")\n",
        "\n",
        "writer.close()"
      ],
      "metadata": {
        "id": "w4R4UGQhuivW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 9: Save and Load Model"
      ],
      "metadata": {
        "id": "DxMKjxp_z-uR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Model"
      ],
      "metadata": {
        "id": "wDV-w_i80EKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '<your_model_name>.pth')"
      ],
      "metadata": {
        "id": "e_GI1Zhz0RJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Model"
      ],
      "metadata": {
        "id": "_X16XaPu0VFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('<your_model_path>.pth'))"
      ],
      "metadata": {
        "id": "DULunPVB0bQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 10: Evaluation and Inference"
      ],
      "metadata": {
        "id": "GbFIqinsyR2t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Evaluation"
      ],
      "metadata": {
        "id": "8dtcGIYNyVLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "model = ssdlite320_mobilenet_v3_large(pretrained=True)\n",
        "\n",
        "model.load_state_dict(torch.load(r'<your_model_path>.pth'))\n",
        "model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.eval()\n",
        "\n",
        "# Load the validation dataset\n",
        "val_annotation_file = r'<your_val_annotations.json>'\n",
        "coco = COCO(val_annotation_file)\n",
        "img_ids = coco.getImgIds()\n",
        "\n",
        "# Function to convert image id to file path\n",
        "def get_image_path(coco, img_id):\n",
        "    img_info = coco.loadImgs(img_id)[0]\n",
        "    return r'<your_val_dataset_path>\\\\' + img_info['file_name']\n",
        "\n",
        "# Running inference and preparing results for COCO format\n",
        "results = []\n",
        "for img_id in img_ids:\n",
        "    img_path = get_image_path(coco, img_id)\n",
        "    img = Image.open(img_path).convert('RGB')\n",
        "    img_tensor = F.to_tensor(img).unsqueeze(0).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        preds = model(img_tensor)[0]\n",
        "\n",
        "    for box, label, score in zip(preds['boxes'], preds['labels'], preds['scores']):\n",
        "        box = box.cpu().numpy()\n",
        "        bbox = [float(box[0]), float(box[1]), float(box[2] - box[0]), float(box[3] - box[1])]  # Convert to Python floats\n",
        "        results.append({\n",
        "            'image_id': img_id,\n",
        "            'category_id': int(label.cpu().item()),  # Convert to int\n",
        "            'bbox': bbox,\n",
        "            'score': float(score.cpu().item())  # Convert to Python float\n",
        "        })\n",
        "\n",
        "# Write results to a file\n",
        "with open('predictions.json', 'w') as f:\n",
        "    json.dump(results, f)\n",
        "\n",
        "# Load the predictions with COCO API\n",
        "coco_pred = coco.loadRes('predictions.json')\n",
        "\n",
        "# Running the COCO evaluation\n",
        "coco_eval = COCOeval(coco, coco_pred, 'bbox')\n",
        "coco_eval.evaluate()\n",
        "coco_eval.accumulate()\n",
        "coco_eval.summarize()"
      ],
      "metadata": {
        "id": "CwfmAcVLyb2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference and Visualization"
      ],
      "metadata": {
        "id": "4idi9cx013I7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(r'your_model_path>.pth'))\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "# Function to apply the model to an image and draw the results\n",
        "from IPython.display import display\n",
        "\n",
        "def infer_and_draw(image_path, model, device, threshold=0.9):\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    img_tensor = F.to_tensor(img).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        prediction = model([img_tensor])\n",
        "\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    found_boxes = False\n",
        "\n",
        "    for element in range(len(prediction[0]['boxes'])):\n",
        "        score = prediction[0]['scores'][element]\n",
        "        if score > threshold:\n",
        "            found_boxes = True\n",
        "            box = prediction[0]['boxes'][element].cpu().numpy()\n",
        "            label = prediction[0]['labels'][element].cpu().numpy()\n",
        "            label_name = 'Vehicles' if label == 1 else 'Background'\n",
        "\n",
        "            draw.rectangle([(box[0], box[1]), (box[2], box[3])], outline =\"red\", width=3)\n",
        "            draw.text((box[0], box[1]), f\"{label_name}: {score:.2f}\", fill=\"red\")\n",
        "\n",
        "    if found_boxes:\n",
        "        print(\"Bounding boxes found and drawn.\")\n",
        "    else:\n",
        "        print(\"No bounding boxes found above the threshold.\")\n",
        "\n",
        "    return img\n",
        "\n",
        "# Run inference on an image\n",
        "image_path = r'your_image_path>.jpg'\n",
        "result_img = infer_and_draw(image_path, model, device)\n",
        "display(result_img)  # Use this in Jupyter Notebook\n",
        "#result_img.show()  # Use this in a Python script"
      ],
      "metadata": {
        "id": "wC7spt-M2BSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**\n",
        "\n",
        "This notebook is designed to be a user-friendly guide for beginners. By following these steps, you can train a SSD model for vehicle detection or other similar tasks, customize file paths, checkpoint names, and model names as per your requirements."
      ],
      "metadata": {
        "id": "9u92pcL736YW"
      }
    }
  ]
}
